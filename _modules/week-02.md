---
title: Linear Algebra II (singular value decomposition and eigendecomposition)
---
Jul 8
: [Lecture: Singular Value Decomposition]({{ site.baseurl }}/assets/slides/2.1_svd.pdf)
    : [3D SVD (unprojected)]({{ site.baseurl }}/assets/figs/3d_svd.html), [3D SVD (u1, u2)]({{ site.baseurl }}/assets/figs/3d_svd_u1u2.html), [3D SVD (u1)]({{ site.baseurl }}/assets/figs/3d_svd_u1.html), [Orthogonal Complement]({{ site.baseurl }}/assets/figs/ortho_comp.html), [Class Photo Singular Values]({{ site.baseurl }}/assets/figs/rank_k_values.html), [MML 4.2, 4.4, 4.5](https://mml-book.github.io/book/mml-book.pdf), [Daniel Hsu's Computational Linear Algebra (CLA) course notes on SVD](https://www.cs.columbia.edu/~djhsu/coms3251-f22/notes/svd.pdf), [Daniel Hsu's CLA interactive example of "best-fitting 1d subspace"](https://www.cs.columbia.edu/~djhsu/coms3251-f22/bfl.html)
: **DUE**{: .label .label-blue } **Project first evaluation due**

Jul 10
: Lecture: Eigendecomposition, positive semidefinite matrices, and PCA

Jul 11
: **DUE**{: .label .label-blue } **PS 1 due**

LS (Story thus far)
: Lecture 2.1: [The problem of least squares regression is unified under the pseudoinverse.]({{ site.baseurl }}/story_ls/ls2_1.html)

GD (Story thus far)
: Lecture 2.1 (nothing new): [Gradient descent with a "bowl-shaped" function gets us to the minimum.]({{ site.baseurl }}/story_gd/gd1_1.html)
